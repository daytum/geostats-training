{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "\n",
    "<p align=\"center\">\n",
    "    <img src=\"https://github.com/GeostatsGuy/GeostatsPy/blob/master/TCG_color_logo.png?raw=true\" width=\"220\" height=\"240\" />\n",
    "\n",
    "</p>\n",
    "\n",
    "### Interactive Spatial Bootstrap\n",
    "\n",
    "\n",
    "#### Michael Pyrcz, Professor, The University of Texas at Austin \n",
    "\n",
    "##### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for / demonstration of **Bootstrap**. \n",
    "\n",
    "**YouTube Lecture**: check out my lecture on [Bootstrap](https://youtu.be/wCgdoImlLY0?si=lpTWz2H7QTdxHBy9). For your convenience here's a summary of salient points.\n",
    "\n",
    "\n",
    "#### Bootstrap\n",
    "\n",
    "Uncertainty in the sample statistics\n",
    "* one source of uncertainty is the paucity of data.\n",
    "* do 200 or even less wells provide a precise (and accurate estimate) of the mean? standard deviation? skew? P13?\n",
    "\n",
    "Would it be useful to know the uncertainty in these statistics due to limited sampling?\n",
    "* what is the impact of uncertainty in the mean porosity e.g. 20%+/-2%?\n",
    "\n",
    "**Bootstrap** is a method to assess the uncertainty in a sample statistic by repeated random sampling with replacement.\n",
    "\n",
    "Assumptions\n",
    "* sufficient, representative sampling, identical, idependent samples\n",
    "\n",
    "Limitations\n",
    "1. assumes the samples are representative \n",
    "2. assumes stationarity\n",
    "3. only accounts for uncertainty due to too few samples, e.g. no uncertainty due to changes away from data\n",
    "4. does not account for boundary of area of interest \n",
    "5. assumes the samples are independent\n",
    "6. does not account for other local information sources\n",
    "\n",
    "The Bootstrap Approach (Efron, 1982)\n",
    "\n",
    "Statistical resampling procedure to calculate uncertainty in a calculated statistic from the data itself.\n",
    "* Does this work?  Prove it to yourself, for uncertainty in the mean solution is standard error: \n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^2_\\overline{x} = \\frac{\\sigma^2_s}{n}\n",
    "\\end{equation}\n",
    "\n",
    "Extremely powerful - could calculate uncertainty in any statistic!  e.g. P13, skew etc.\n",
    "* Would not be possible access general uncertainty in any statistic without bootstrap.\n",
    "* Advanced forms account for spatial information and sampling strategy (game theory and Journelâ€™s spatial bootstrap (1993).\n",
    "\n",
    "Steps: \n",
    "\n",
    "1. assemble a sample set, must be representative, reasonable to assume independence between samples\n",
    "\n",
    "2. optional: build a cumulative distribution function (CDF)\n",
    "    * may account for declustering weights, tail extrapolation\n",
    "    * could use analogous data to support\n",
    "\n",
    "3. For $\\ell = 1, \\ldots, L$ realizations, do the following:\n",
    "\n",
    "    * For $i = \\alpha, \\ldots, n$ data, do the following:\n",
    "\n",
    "        * Draw a random sample with replacement from the sample set or Monte Carlo simulate from the CDF (if available). \n",
    "\n",
    "6. Calculate a realization of the sammary statistic of interest from the $n$ samples, e.g. $m^\\ell$, $\\sigma^2_{\\ell}$. Return to 3 for another realization.\n",
    "\n",
    "7. Compile and summarize the $L$ realizations of the statistic of interest.\n",
    "\n",
    "#### Spatial Bootstrap\n",
    "\n",
    "Journel (1993) developed methods for spatial bootstrap based on bootstrap resampling accounting for the locations of the data and the spatial continuity model.  \n",
    "\n",
    "* One method to perform spatial bootstrap for uncertainty of a statistic is to adjust the number of data, $n$, to the **number of effective data**, then use the number of effective data instead of number of data of resamples with replacement for each bootstrap realization.\n",
    "\n",
    "This number of effectve data may be calculated by:\n",
    "\n",
    "* building multiple unconditional simulated realizations at the data locations only \n",
    "\n",
    "* calculating the variance of the average of each simulated realization\n",
    "\n",
    "* then calculate the number effective data by manipulating the standard error in the average equation:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^2_\\overline{x} = \\frac{\\sigma^2}{n}\n",
    "\\end{equation}\n",
    "\n",
    "to be expressed as:\n",
    "\n",
    "\\begin{equation}\n",
    "n^{'} = \\frac{\\sigma^2}{\\sigma^2_\\overline{x}}\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma^2_\\overline{x}$ is the variance of the average over bootstrap realizations $\\ell = 1,\\ldots,L$, $\\sigma^2$ is the variance / sill of the problem.\n",
    "\n",
    "#### Simulating Only at the Data Locations\n",
    "\n",
    "We ultilize LU Simulation to efficiently calculate Gaussian realizations only at the data locations, based on the Lower-Upper Decomposition of the left-hand / redudancy martix of the simple kriging.  \n",
    "\n",
    "* We multiple the Lower matrix ($n \\times n$) with a random Gaussian vector ($1 \\times n$) to calculate each realization at the data locations.\n",
    "\n",
    "* We then take the average of each realization and then calculate the variance of the average over enough realizations.\n",
    "\n",
    "\n",
    "\n",
    "This is a very powerful method, but it ignores the spatial context!\n",
    "\n",
    "* here I provide demonstrations for spatial bootstrap, a variant of bootstrap that accounts for the spatial context.\n",
    "\n",
    "#### Load the required libraries\n",
    "\n",
    "The following code loads the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeostatsPy version: 0.0.72\n"
     ]
    }
   ],
   "source": [
    "import geostatspy.GSLIB as GSLIB                              # GSLIB utilies, visualization and wrapper\n",
    "import geostatspy.geostats as geostats                        # GSLIB methods convert to Python      \n",
    "import geostatspy\n",
    "print('GeostatsPy version: ' + str(geostatspy.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also need some standard packages. These should have been installed with Anaconda 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "supress_warnings = True                                       # supress warnings?\n",
    "ignore_warnings = True                                        # ignore warnings?\n",
    "import numpy as np                                            # ndarrys for gridded data\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt                               # for plotting\n",
    "import statsmodels.api as sm                                  # make PDFs\n",
    "import math\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator) # control of axes ticks\n",
    "import scipy as sp                                            # lower upper matrix decomposition\n",
    "from scipy.interpolate import make_interp_spline              # smooth curves\n",
    "import statsmodels.formula.api as smf    \n",
    "from scipy.stats import norm                                  # Gaussian distribution PDF and sampling\n",
    "import geostatspy.GSLIB as GSLIB    \n",
    "import geostatspy.geostats as geostats    \n",
    "import scipy.signal as signal                                 # kernel for convolution\n",
    "from scipy import ndimage                               \n",
    "from scipy import stats    \n",
    "from ipywidgets import interactive                            # widgets and interactivity\n",
    "from ipywidgets import widgets                                \n",
    "from ipywidgets import Layout\n",
    "from ipywidgets import Label\n",
    "from ipywidgets import VBox, HBox\n",
    "plt.rc('axes', axisbelow=True)                            # grid behind plotting elements\n",
    "if supress_warnings == True:\n",
    "    import warnings                                       # supress any warnings for this demonstration\n",
    "    warnings.filterwarnings('ignore')                  \n",
    "cmap = plt.cm.inferno                                     # default color bar, no bias and friendly for color vision defeciency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you get a package import error, you may have to first install some of these packages. This can usually be accomplished by opening up a command window on Windows and then typing 'python -m pip install [package-name]'. More assistance is available with the respective package docs.  \n",
    "\n",
    "#### Declare Functions\n",
    "\n",
    "I just added a convenience functions to:\n",
    "\n",
    "1. add major and minor gridlines\n",
    "2. calculate a isotropic variogram between 2 points\n",
    "3. calculate the azimuth between 2 points to rotate a label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_grid():\n",
    "    plt.gca().grid(True, which='major',linewidth = 1.0); plt.gca().grid(True, which='minor',linewidth = 0.2) # add y grids\n",
    "    plt.gca().tick_params(which='major',length=7); plt.gca().tick_params(which='minor', length=4)\n",
    "    plt.gca().xaxis.set_minor_locator(AutoMinorLocator()); plt.gca().yaxis.set_minor_locator(AutoMinorLocator()) # turn on minor ticks     \n",
    "\n",
    "def n_effective(df,xcol,ycol,seed,nreal,vario):\n",
    "    \"\"\"Calculate the number of effective data from spatial locations and spatial continuity model\n",
    "    Used in bootstrap to account for spatial continuity, use n effective instead of number of data\n",
    "    :param df: source DataFrame\n",
    "    :param xcol: column with the X locations\n",
    "    :param ycol: column with the Y locations\n",
    "    :param seed: random number seed for the random sampling\n",
    "    :param nreal: number of realizations to sample the variance of the average \n",
    "    :param vario: variogram model as a dictionary, see the GeostatsPy Package's GSLIB.make_variogram() function \n",
    "    :return: n_eff as effective number of data\n",
    "    \"\"\" \n",
    "\n",
    "# Set constants\n",
    "    np.random.seed(seed)\n",
    "    PMX = 9999.9\n",
    "    \n",
    "# load the variogram\n",
    "    nst = vario['nst']\n",
    "    cc = np.zeros(nst); aa = np.zeros(nst); it = np.zeros(nst)\n",
    "    ang = np.zeros(nst); anis = np.zeros(nst)\n",
    "    c0 = vario['nug']; \n",
    "    cc[0] = vario['cc1']; it[0] = vario['it1']; ang[0] = vario['azi1']; \n",
    "    aa[0] = vario['hmaj1']; anis[0] = vario['hmin1']/vario['hmaj1'];\n",
    "    if nst == 2:                                   # include 2nd structure if present (optional)\n",
    "        cc[1] = vario['cc2']; it[1] = vario['it2']; ang[1] = vario['azi2']; \n",
    "        aa[1] = vario['hmaj2']; anis[1] = vario['hmin2']/vario['hmaj2'];\n",
    "    \n",
    "# Set up the rotation matrix\n",
    "    rotmat, maxcov = geostats.setup_rotmat(c0,nst,it,cc,ang,PMX)\n",
    "    \n",
    "# Load the data\n",
    "    nd = len(df)\n",
    "    x = df[xcol].values\n",
    "    y = df[ycol].values\n",
    "    \n",
    "# Calculate Symmetric Covariance Array - assuming variogram with spherical structure with range specified\n",
    "    cov = np.zeros((nd,nd))\n",
    "    var_range = 100.0\n",
    "    for i in range(0, nd):\n",
    "        x1 = x[i]; y1 = y[i]\n",
    "        for j in range(0, nd):\n",
    "            x2 = x[j]; y2 = y[j]\n",
    "            cova = geostats.cova2(x1, y1, x2, y2, nst, c0, PMX, cc, aa, it, ang, anis, rotmat, maxcov)\n",
    "            cov[i,j] = cova\n",
    "            \n",
    "# Lower and upper deconvolution            \n",
    "    P, L, U = sp.linalg.lu(cov) \n",
    "    \n",
    "# Build realization and calculate the average    \n",
    "    realizations = np.zeros((nreal,nd))\n",
    "    average_array = np.zeros(nreal)\n",
    "    rand = np.zeros((nd)) \n",
    "    for l in range(0, nreal):\n",
    "        rand = np.random.normal(loc = 0.0, scale = 1.0, size = nd)\n",
    "        realizations[l,:] = np.matmul(L,rand)\n",
    "        average_array[l] = np.average(realizations[l])\n",
    "        \n",
    "# Back out the number of effecitve data useing the standard error in the average\n",
    "    var_average = np.var(average_array)\n",
    "    n_eff = max(min(1.0/var_average, nd),1.0)    # filter n effective less than 1.0 or greater than number of data\n",
    "    return n_eff, realizations\n",
    "    \n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = 'percentile_%s' % n\n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n Effective Demonstration\n",
    "\n",
    "This dashboard visualizes the impact of spatial continuity range and number of samples on the effective number of data. \n",
    "\n",
    "* How many independent peices of information do you have given spatial correlation between the samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_L = 100                                                   # maximum number of realizations to precalculate\n",
    "\n",
    "l = widgets.Text(value=r'                                                      Number of Effective Data, Michael Pyrcz, Professor, The University of Texas at Austin',layout=Layout(width='950px', height='30px'))\n",
    "\n",
    "n = widgets.IntSlider(min=1, max = max_L, value = 1,step = 1,description = 'n',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "n.style.handle_color = 'gray'\n",
    "\n",
    "vrange = widgets.FloatSlider(min=0.1, max = 200.0, value = 10.0,step=5,description = 'range',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "vrange.style.handle_color = 'gray'\n",
    "\n",
    "seed = widgets.IntSlider(min=100, max = 999, value = 1, description = 's',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "seed.style.handle_color = 'gray'\n",
    "\n",
    "window = widgets.Checkbox(value=False,description='Conv. Fit',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "poly = widgets.Checkbox(value=True,description='Poly. Fit',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "\n",
    "ui1 = widgets.HBox([n,vrange,seed,],kwargs = {'justify_content':'center'})\n",
    "ui2 = widgets.HBox([window,poly,],kwargs = {'justify_content':'center'})\n",
    "ui_all = widgets.VBox([l,ui1,ui2],)\n",
    "\n",
    "def f_make1(n,vrange,seed,window,poly): \n",
    "    np.random.seed(seed=seed)\n",
    "    values = np.random.rand(max_L*2)*100\n",
    "    X,Y = np.split(values,2)\n",
    "    df = pd.DataFrame(np.vstack((X[:n],Y[:n])).T,columns = ['X','Y'])\n",
    "    \n",
    "    ax1 = plt.subplot(121)\n",
    "    plt.scatter(df['X'],df['Y'],color='red',edgecolor='black',zorder=10,label = 'Spatial Data')\n",
    "    plt.gca().add_patch(plt.Rectangle((0, 0), 100, 100, fill=False,edgecolor='black',lw=2))\n",
    "    \n",
    "    for ipts in range(0,n):\n",
    "        if ipts == 0:\n",
    "            circle1 = plt.Circle((df['X'][ipts],df['Y'][ipts]),vrange,fill=True,color='red',edgecolor=None,\n",
    "                lw=0.0,alpha=0.1,zorder=1,label='Spatial Continuity')\n",
    "        else:\n",
    "            circle1 = plt.Circle((df['X'][ipts],df['Y'][ipts]),vrange,fill=True,color='red',edgecolor=None,\n",
    "                lw=0.0,alpha=0.1,zorder=1)\n",
    "        plt.gca().add_patch(circle1)\n",
    "    \n",
    "    plt.xlim([-10,110]); plt.ylim([-10,110]); add_grid(); plt.xlabel(\"X (m)\"); plt.ylabel(\"Y (m)\") \n",
    "    plt.title('Random Spatial Dataset with Spatial Correlation Range Indicated')\n",
    "    \n",
    "    vario = GSLIB.make_variogram(nug=0.0,nst=1,it1=1,cc1=1.0,azi1=0.0,hmaj1=vrange,hmin1=vrange)\n",
    "    neffective = n_effective(df,'X','Y',seed=seed,nreal=1000,vario=vario)[0]\n",
    "    \n",
    "    neffect_array = []; l_array = []\n",
    "    for l in np.arange(1,max_L,2):\n",
    "        l_array.append(l)\n",
    "        df = pd.DataFrame(np.vstack((X[:l],Y[:l])).T,columns = ['X','Y'])\n",
    "        neffect_array.append(n_effective(df,'X','Y',seed=seed,nreal=1000,vario=vario)[0])\n",
    "    \n",
    "    df_effective = pd.DataFrame(np.vstack((l_array,neffect_array)).T,columns = ['l','e'])    \n",
    "    olsres2 = smf.ols(formula = 'e ~ l + I(l**2)+ I(l**3)-1', data = df_effective).fit()    \n",
    "      \n",
    "    plt.annotate(r'$n$ = ' + str(np.round(n,2)),(0,-5))\n",
    "    plt.annotate(r'$n_{effective}$ = ' + str(np.round(neffective,2)),(15,-5))\n",
    "    neffective_model = olsres2.params[2]*np.power(n,3) + olsres2.params[1]*np.power(n,2) + olsres2.params[0]*n\n",
    "    plt.annotate(r'$\\hat{n}_{effective}$ = ' + str(np.round(neffective_model,2)),(42,-5))\n",
    "    plt.legend(loc = 'upper left')\n",
    "        \n",
    "    ax2 = plt.subplot(122)\n",
    "    plt.plot([1,max_L],[1,max_L],color='black')\n",
    "    plt.scatter(n,neffective,c='red',edgecolor='black',s=20,zorder=10)\n",
    "    plt.scatter(n,neffective_model,c='darkorange',edgecolor='black',s=20,zorder=10)\n",
    "    plt.scatter(l_array,neffect_array,c='grey',edgecolor='grey',lw=0,s=30,alpha=0.4,zorder=5)\n",
    "    kernel = np.array([0.076923,0.230769,0.384615,0.230769,0.076923])\n",
    "    #plt.plot(np.arange(1,max_L+1,1),poly(np.arange(1,max_L+1,1)),c='red',zorder=1) \n",
    "    if window:\n",
    "        plt.plot(l_array[2:-2],np.convolve(neffect_array,kernel,mode = 'valid'),c='red',zorder=1) \n",
    "    # plt.plot(np.arange(1,max_L,3),max_pool,c='red',zorder=1) \n",
    "    if poly:\n",
    "        xs = np.arange(1,max_L,1)\n",
    "        neff_poly_model = olsres2.params[2]*np.power(xs,3) + olsres2.params[1]*np.power(xs,2) + olsres2.params[0]*xs\n",
    "        plt.plot(xs,neff_poly_model,color='darkorange',zorder=10)\n",
    "        plt.fill_between(xs,neff_poly_model,np.zeros(len(xs)),color='darkorange',alpha=0.2,zorder=1,label='Effective')\n",
    "        plt.fill_between(xs,xs,neff_poly_model,color='grey',alpha=0.2,zorder=1,label='Ineffective')\n",
    "        plt.legend(loc='upper left')\n",
    "        \n",
    "    plt.plot([0,n],[n,n],c='grey',zorder=3)\n",
    "    plt.plot([n,n],[0,n],c='grey',zorder=3)\n",
    "\n",
    "    if n > 10: \n",
    "        plt.annotate('No Spatial Correlation = ' + str(np.round(n,2)),[1.2,n+0.4],c='grey',zorder=3)\n",
    "        if abs(n - neffective) > 1.5:\n",
    "            plt.annotate('With Spatial Correlation = ' + str(np.round(neffective_model,2)),[1.2,neffective_model+0.4],c='darkorange',zorder=5)\n",
    "            plt.plot([n,n],[0,neffective_model],c='darkorange',zorder=5); \n",
    "            plt.plot([0,n],[neffective_model,neffective_model],c='darkorange',zorder=5) \n",
    "    \n",
    "    plt.ylim([1,max_L]); plt.xlim([1,max_L]); plt.xscale(\"linear\"); plt.yscale(\"linear\")\n",
    "    plt.xlabel(\"Number of Samples\"); plt.ylabel(\"Number of Independent Samples\"); plt.title(r'Number of Independent Samples ($n_{effective}$) vs. Number of Samples')\n",
    "    add_grid()\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2); \n",
    "    plt.savefig('SpatialBootstrap.jpg',dpi=600,bbox_inches='tight')  \n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot1 = widgets.interactive_output(f_make1, {'n':n,'vrange':vrange,'seed':seed,'window':window,'poly':poly})\n",
    "interactive_plot1.clear_output(wait = True)                # reduce flickering by delaying plot updating  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfba8c92a88425e97fcd8762dfb107d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='                                                      Number of Effective Data, Micâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0439c0c8239a4191a173e9e6a215831a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_all, interactive_plot1)                            # display the interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spatial Bootstrap Demonstrations\n",
    "\n",
    "I provide two methods for spatial bootstrap.\n",
    "\n",
    "##### Spatial Bootstrap by Unconditional Simulation at Data Locations\n",
    "\n",
    "This is the method proposed by Professor Deutsch with unconditional simulation at the data locations with a computationally efficient LUSIM approach, based on lower and upper decomposition of the covariance matrix.\n",
    "\n",
    "* Under the assumption of stationary histogram, variogram\n",
    "* simulation is conducted in Gaussian space, but may be transformed to other distributions\n",
    "\n",
    "Here we visualize the spatial bootstrap, bootstrap accounting for data location and the spatial correlation via the variogram. \n",
    "\n",
    "* How many independent pieces of information do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreal = 100                                                   # number of realizations\n",
    "tmean = 1000; tstdev = 200                                    # distribution mean and standard deviation\n",
    "l = widgets.Text(value=r'                                       Spatial Bootstrap for Uncertainty in the Mean, Michael Pyrcz, Professor, The University of Texas at Austin',layout=Layout(width='950px', height='30px'))\n",
    "\n",
    "n = widgets.IntSlider(min=1, max = max_L, value = 1,step = 1,description = 'n',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "n.style.handle_color = 'gray'\n",
    "\n",
    "vrange = widgets.FloatSlider(min=0.1, max = 200.0, value = 10.0,step=5,description = 'range',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "vrange.style.handle_color = 'gray'\n",
    "\n",
    "ireal = widgets.IntSlider(min=1, max = nreal, value = 1,step = 1,description = 'l',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "ireal.style.handle_color = 'gray'\n",
    "\n",
    "seed = widgets.IntSlider(min=100, max = 999, value = 1, description = 's',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "seed.style.handle_color = 'gray'\n",
    "\n",
    "window = widgets.Checkbox(value=False,description='Conv. Fit',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "poly = widgets.Checkbox(value=True,description='Poly. Fit',disabled=False,layout=Layout(width='200px', height='30px'))\n",
    "\n",
    "ui1 = widgets.HBox([n,vrange,ireal,seed,],kwargs = {'justify_content':'center'})\n",
    "ui2 = widgets.HBox([window,poly,],kwargs = {'justify_content':'center'})\n",
    "ui_all2 = widgets.VBox([l,ui1,ui2],)\n",
    "\n",
    "def f_make2(n,vrange,ireal,seed,window,poly):\n",
    "    \n",
    "    nreal = 100;\n",
    "    maxf = 50; maxfboot = 15\n",
    "    dx = -5; dy = 3; pdfy = 13.0\n",
    "    \n",
    "    np.random.seed(seed=seed)\n",
    "    locations = np.random.rand(max_L*2)*100\n",
    "    X,Y = np.split(locations,2)\n",
    "    df = pd.DataFrame(np.vstack((X[:n],Y[:n])).T,columns = ['X','Y'])\n",
    "    \n",
    "    ax1 = plt.subplot(121)\n",
    "    plt.scatter(df['X'],df['Y'],marker='x',s=30,color='red',edgecolor='black',lw=2,zorder=10,label = 'Spatial Data')\n",
    "    plt.scatter(df['X'],df['Y'],marker='x',s=40,color='white',edgecolor='black',lw=4,zorder=9,label = 'Spatial Data')\n",
    "    plt.gca().add_patch(plt.Rectangle((0, 0), 100, 100, fill=False,edgecolor='black',lw=2))\n",
    "    \n",
    "    xx = np.arange(-3,3,0.1)\n",
    "    pdf = norm.pdf(xx, loc=0, scale=1) * pdfy\n",
    "    px = np.linspace(0,10,len(xx))\n",
    "    \n",
    "    for ipts in range(0,n):\n",
    "        if ipts == 0:\n",
    "            circle1 = plt.Circle((df['X'][ipts],df['Y'][ipts]),vrange,fill=True,color='red',edgecolor=None,\n",
    "                lw=0.0,alpha=0.05,zorder=1,label='Spatial Continuity')\n",
    "        else:\n",
    "            circle1 = plt.Circle((df['X'][ipts],df['Y'][ipts]),vrange,fill=True,color='red',edgecolor=None,\n",
    "                lw=0.0,alpha=0.05,zorder=1)\n",
    "        plt.gca().add_patch(circle1)\n",
    "        \n",
    "        plt.plot([df['X'][ipts]+dx,df['X'][ipts]+10+dx],[df['Y'][ipts]+dy,df['Y'][ipts]+dy],color='black')\n",
    "        plt.plot([df['X'][ipts]+dx,df['X'][ipts]+dx],[df['Y'][ipts]+dy,df['Y'][ipts]+5+dy],color='black')\n",
    "        plt.plot(px + df['X'][ipts] + dx,pdf + df['Y'][ipts] + dy,color = 'black',zorder=1)\n",
    "    \n",
    "    plt.xlim([-10,110]); plt.ylim([-10,110]); add_grid(); plt.xlabel(\"X (m)\"); plt.ylabel(\"Y (m)\") \n",
    "    plt.title('Random Spatial Dataset with Spatial Correlation Range Indicated')\n",
    "    \n",
    "    vario = GSLIB.make_variogram(nug=0.0,nst=1,it1=1,cc1=1.0,azi1=0.0,hmaj1=vrange,hmin1=vrange)\n",
    "    neffective,realizations = n_effective(df,'X','Y',seed=seed,nreal=nreal,vario=vario)\n",
    "    \n",
    "    realizations = realizations*tstdev+tmean       # correct distribution from N[0,1] to target mean and st.dev.\n",
    "    \n",
    "    for ipts in range(0,n):\n",
    "        y = df['Y'][ipts]+dy; x = df['X'][ipts]+dx+(realizations[ireal-1,ipts]-0.0)/2000.0*10\n",
    "        plt.plot([x,x],[y,y+5],color='black',lw=3,zorder=1); plt.plot([x,x],[y,y+5],color='red',lw=1,zorder=3)\n",
    "    \n",
    "    ax2 = plt.subplot(122)\n",
    "    plt.axis('off'); plt.xlim([0, 10]); plt.ylim([0, 10])\n",
    "    \n",
    "    oxp = 2.0; oyp = 6.7; xprange = 6.0; yprange = 3.0 # location of histogram of bootstrap realization\n",
    "    xmin = 0.0; xmax = 2000.0; ymin = 0.0; ymax = maxfboot; nbin = 11\n",
    "    \n",
    "    plt.plot([oxp,oxp+xprange],[oyp,oyp],color='black'); plt.plot([oxp,oxp],[oyp,oyp+yprange],color='black')\n",
    "    \n",
    "    xpmin = oxp; xpmax = oxp+xprange; ypmin = oyp; ypmax = oyp+yprange\n",
    "    xrange = xmax - xmin; yrange = ymax - ymin\n",
    "    xhalf = (xmax-xmin)/(nbin-1)/2.0; xsize = xhalf*2.0\n",
    "    xxhalf = xhalf*xprange/xrange; xxsize = xsize*xprange/xrange \n",
    "\n",
    "    xbins = np.linspace(xmin,xmax,nbin)\n",
    "    ybins = np.linspace(ymin,maxfboot,11)\n",
    "    xcents = np.linspace(xmin + xhalf,xmax-xhalf,nbin-1)\n",
    "    \n",
    "    for ibin, xbin in enumerate(xbins):\n",
    "        xx = ((xbin-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xx,xx],[ypmin,ypmax],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 2 == 0:\n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.1,ypmin],color='black',zorder=3)\n",
    "            plt.annotate(np.round(xbin,1),(xx,ypmin-yprange*0.20),ha='center')\n",
    "        else: \n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.05,ypmin],color='black',zorder=3)\n",
    "            plt.annotate(np.round(xbin,1),(xx,ypmin-yprange*0.13),ha='center')\n",
    "    \n",
    "    for ybin in ybins:\n",
    "        #yy = (ybin)*3/maxfboot+6\n",
    "        yy = ((ybin-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot([xpmin-xprange*0.04,xpmin],[yy,yy],color='black',zorder=3)\n",
    "        plt.plot([xpmin,xpmax],[yy,yy],color='grey',lw=0.2,zorder=1)\n",
    "        plt.annotate(np.round(ybin,1),(xpmin-xprange*0.05,yy),ha='right')\n",
    "    \n",
    "    histboot = np.histogram(realizations[ireal-1,:], bins=xbins, weights=None)[0]\n",
    "    average = np.average(realizations[ireal-1,:])\n",
    "    \n",
    "    for ibin, prop in enumerate(histboot):\n",
    "        xx = ((xcents[ibin]-xmin)/xrange*xprange)+xpmin\n",
    "        yy = histboot[ibin]*yprange/maxfboot\n",
    "        ax2.add_patch(plt.Rectangle((xx-xxhalf,ypmin), xxsize, yy, lw=1, fc = 'darkorange',color='black', ))\n",
    "        xavg = ((average-xmin)/xrange*xprange)+xpmin\n",
    "        \n",
    "    for ipts in range(0,n):\n",
    "        xx = ((realizations[ireal-1,ipts]-xmin)/xrange*xprange)+xpmin \n",
    "        plt.scatter(xx,ypmin,color='red',edgecolor='black',s=20,alpha=1.0,zorder=100)\n",
    "       \n",
    "    plot_avg = True\n",
    "    if plot_avg:\n",
    "        xx = ((np.average(realizations[ireal-1,:])-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xx,xx],[ypmin,ypmax],color='red',lw=2,ls='--')\n",
    "        plt.annotate(r'$\\overline{x}^{\\ell} = $' + str(np.round(np.average(realizations[ireal-1,:]),2)),\n",
    "                     (xx,ypmin+yprange*0.8),color='red',rotation=270,va='center')\n",
    "        \n",
    "    plt.annotate('Spatial Bootstrap Distribution Realization #' + str(ireal),(xpmin+xprange*0.5,ypmax+yprange*0.08),ha='center') \n",
    "    plt.annotate('Lithium Grade (ppm)',(xpmin+xprange*0.5,ypmin-yprange*0.27),ha='center') \n",
    "    plt.annotate('Frequency',(xpmin-xprange*0.18,ypmin+yprange*0.5),va='center',rotation = 90.0)   \n",
    "    \n",
    "    oxp = 2.0; oyp = 2.3; xprange = 6.0; yprange = 3.0 # location of histogram of averages\n",
    "    xmin = 0.0; xmax = 2000.0; ymin = 0.0; ymax = maxfboot; nbin = 11\n",
    "       \n",
    "    xpmin = oxp; xpmax = oxp+xprange; ypmin = oyp; ypmax = oyp+yprange\n",
    "    xrange = xmax - xmin; yrange = ymax - ymin\n",
    "    xhalf = (xmax-xmin)/(nbin-1)/2.0; xsize = xhalf*2.0\n",
    "    xxhalf = xhalf*xprange/xrange; xxsize = xsize*xprange/xrange\n",
    "    xbins = np.linspace(xmin,xmax,nbin)\n",
    "    ybins = np.linspace(ymin,maxfboot,11)\n",
    "    xcents = np.linspace(xmin + xhalf,xmax-xhalf,nbin-1)\n",
    "    xvalues = np.linspace(xmin,xmax,100)\n",
    "    \n",
    "    plt.plot([oxp,oxp+xprange],[oyp,oyp],color='black'); plt.plot([oxp,oxp],[oyp,oyp+yprange],color='black')\n",
    "    \n",
    "    for ibin, xbin in enumerate(xbins):\n",
    "        xx = ((xbin-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xx,xx],[ypmin,ypmax],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 2 == 0:\n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.1,ypmin],color='black',zorder=3)\n",
    "            plt.annotate(np.round(xbin,1),(xx,ypmin-yprange*0.20),ha='center')\n",
    "        else: \n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.05,ypmin],color='black',zorder=3)\n",
    "            plt.annotate(np.round(xbin,1),(xx,ypmin-yprange*0.13),ha='center')\n",
    "                 \n",
    "    for ybin in ybins:\n",
    "        yy = ((ybin-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot([xpmin-xprange*0.04,xpmin],[yy,yy],color='black',zorder=3)\n",
    "        plt.plot([xpmin,xpmax],[yy,yy],color='grey',lw=0.2,zorder=1)\n",
    "        plt.annotate(np.round(ybin,1),(xpmin-xprange*0.05,yy),ha='right')\n",
    "        \n",
    "    averages = np.average(realizations,axis=1)\n",
    "    average = np.average(averages[:ireal])\n",
    "    hist_avg = np.histogram(averages[:ireal], bins=xbins, weights=None)[0]\n",
    "    \n",
    "    for ibin, prop in enumerate(hist_avg):\n",
    "        xx = ((xcents[ibin]-xmin)/xrange*xprange)+xpmin\n",
    "        yy = hist_avg[ibin]*3/maxf\n",
    "        ax2.add_patch(plt.Rectangle((xx-xxhalf,ypmin), xxsize, yy, lw=1, fc = 'gold',color='black',zorder=10))\n",
    "        \n",
    "    if ireal > 1:\n",
    "        hist_avg_prior = np.histogram(averages[:ireal-1], bins=xbins, weights=None)[0]\n",
    "        for ibin, prop in enumerate(hist_avg):\n",
    "            yy = hist_avg_prior[ibin]*3/maxf\n",
    "            xx = ((xcents[ibin]-xmin)/xrange*xprange)+xpmin\n",
    "            ax2.add_patch(plt.Rectangle((xx-xxhalf,ypmin), xxsize, yy, lw=1, fc = 'darkorange',color='black',zorder=15))\n",
    "        \n",
    "    plt.annotate('Spatial Bootstrap Average Realizations',(xpmin+xprange*0.5,ypmax+yprange*0.08),ha='center') \n",
    "    plt.annotate('Bootstrap Average Lithium Grade (ppm)',(xpmin+xprange*0.5,ypmin-yprange*0.30),ha='center') \n",
    "    plt.annotate('Frequency',(xpmin-xprange*0.18,ypmin+yprange*0.5),va='center',rotation = 90.0) \n",
    "    \n",
    "    mean = np.average(averages[:ireal]); stdev = np.std(averages[:ireal])\n",
    "    P10 = np.percentile(averages[:ireal],10); P90 = np.percentile(averages[:ireal],90)\n",
    "    plt.annotate('Spatial Bootstrap Uncertainty in Mean:',(0,0.8))\n",
    "    plt.annotate('Mean: ' + str(np.round(mean,2)),(0,0.4),ha='left')\n",
    "    plt.annotate('St.Dev.: ' + str(np.round(stdev,2)),(2.0,0.4),ha='left')\n",
    "    plt.annotate('P10: ' + str(np.round(P10,2)),(0.0,0.0),ha='left')\n",
    "    plt.annotate('P90: ' + str(np.round(P90,2)),(2.0,0.0),ha='left')\n",
    "    \n",
    "    if ireal > 1:\n",
    "        xxmean = ((mean-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xxmean,xxmean],[ypmin,ypmax],color='red',lw=2.0,zorder=100)\n",
    "        plt.annotate('Mean: ' + str(np.round(mean,2)),(xxmean,ypmin+yprange*0.9),rotation=270.0,color='red',va='top')\n",
    "        \n",
    "        xxP10 = ((P10-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xxP10,xxP10],[ypmin,ypmax],color='red',lw=2.0,ls='--',zorder=100)\n",
    "        plt.annotate('P10: ' + str(np.round(P10,2)),(xxP10,ypmin+yprange*0.9),rotation=270.0,color='red',va='top')\n",
    "        \n",
    "        xxP90 = ((P90-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xxP90,xxP90],[ypmin,ypmax],color='red',lw=2.0,ls='--',zorder=100)\n",
    "        plt.annotate('P90: ' + str(np.round(P90,2)),(xxP90,ypmin+yprange*0.9),rotation=270.0,color='red',va='top')\n",
    "       \n",
    "    if ireal > 5:\n",
    "        PDFModel = sm.nonparametric.KDEUnivariate(averages[:ireal]).fit()\n",
    "        yPDF = PDFModel.evaluate(xvalues)*len(averages[:ireal])*xsize/3.0\n",
    "        xxvalues = ((xvalues-xmin)/xrange*xprange)+xpmin; yyPDF = ((yPDF-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot(xxvalues,yyPDF,color='black',zorder=200)\n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=2.0, top=1.2, wspace=0.2, hspace=0.2)\n",
    "    plt.savefig('SpatialBootstrap.jpg',dpi=600,bbox_inches='tight')  \n",
    "    plt.show()\n",
    "    \n",
    "interactive_plot2 = widgets.interactive_output(f_make2, {'n':n,'vrange':vrange,'ireal':ireal,'seed':seed,'window':window,'poly':poly})\n",
    "interactive_plot2.clear_output(wait = True)                # reduce flickering by delaying plot updating     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead716c599c3453f81e2679e32aecd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='                                       Spatial Bootstrap for Uncertainty in the Meaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c7382795b214b7cb9b8e13657f11397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_all2, interactive_plot2)                            # display the interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Spatial Bootstrap By Sampling from Images\n",
    "\n",
    "This is the method proposed by Prof. Journel (SCRF).\n",
    "\n",
    "* this method is general and does not require a specific spatial continuity model nor distribution assumption\n",
    "\n",
    "* we assume stationarity of the specific spatial patterns, as we use sample translation to access replicates\n",
    "\n",
    "###### Make a Stochastic Image\n",
    "\n",
    "We use the convolutional approach to calculating a unconditional sequential Gaussian simulation by:\n",
    "    \n",
    "1. Calculate a set of random Gaussian values over the area of interest. Note, we add padding equal to half the kernel size to avoid edge effects.\n",
    "\n",
    "2. Convolution with a anisotropic, unbiased kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmean = 1000.0; tstdev = 200.0; vmin = 400.0; vmax = 1600.0   # lithium grade distribution (ppm)\n",
    "nx = 50; ny = 50; xmin = 0; xmax = 1000; ymin = 0.0; ymax = 1000.0 # specify the grid\n",
    "\n",
    "xrange = xmax - xmin; yrange = ymax - ymin\n",
    "xsiz = xrange/nx; ysiz = yrange/ny\n",
    "xmn = xmin + xsiz/2.0; ymn = ymin + ysiz/2.0; \n",
    "\n",
    "npadding = 30; nky = 31; nkx = 31; cky = nky/2; ckx = nky/2; vrangex = 150; vrangey = 50 #specify the kernel\n",
    "\n",
    "kernel = np.zeros((nky,nkx)); geo_dist = np.zeros((nky,nkx))  # make the kernel\n",
    "for iy in range(0,nky):\n",
    "    for ix in range(0,nkx):\n",
    "        geo_dist[iy,ix] = 1/(((ix-ckx)*xsiz/vrangex)**2 + ((iy-cky)*ysiz/vrangey)**2 + 0.1)           \n",
    "\n",
    "kernel[geo_dist > 1.0] = 1.0\n",
    "kernel = kernel / np.sum(kernel.flatten())                    # unbiasedness, sum to 1.0\n",
    "\n",
    "pfield = np.random.normal(size=(ny+npadding*2,nx+npadding*2))\n",
    "pfield = signal.fftconvolve(pfield,kernel,mode='same')        # convolution\n",
    "\n",
    "pfield = np.reshape(pfield[npadding:-npadding,npadding:-npadding],(ny,nx))\n",
    "pfield = GSLIB.affine(pfield,tmean,tstdev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Dashboard with Spatial Bootstrap from an Image / Model\n",
    "\n",
    "Here's the dashboard for spatial bootstrap from an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "nreal = 100                                                   # number of realizations\n",
    "l = widgets.Text(value=r'                Spatial Bootstrap, Resampling from Images or Models for Uncertainty in the Mean, Michael Pyrcz, Professor, The University of Texas at Austin',layout=Layout(width='950px', height='30px'))\n",
    "\n",
    "n = widgets.IntSlider(min=1, max = max_L, value = 1,step = 1,description = 'n',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "n.style.handle_color = 'gray'\n",
    "\n",
    "ireal = widgets.IntSlider(min=1, max = nreal, value = 1,step = 1,description = 'l',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "ireal.style.handle_color = 'gray'\n",
    "\n",
    "seed = widgets.IntSlider(min=100, max = 999, value = 1, description = 's',orientation='horizontal',layout=Layout(width='300px', height='50px'),continuous_update=False)\n",
    "seed.style.handle_color = 'gray'\n",
    "\n",
    "ui5 = widgets.HBox([n,ireal,seed,],kwargs = {'justify_content':'center'})\n",
    "ui_all3 = widgets.VBox([l,ui5],)\n",
    "\n",
    "def f_make3(n,ireal,seed,):\n",
    "  \n",
    "    maxf = 50; maxfboot = 15                                      # histogram maximum frequncies on the plots\n",
    "    dx = -5; dy = 3; pdfy = 13.0\n",
    "    template = 200.0; tsize = 5.0                                 # data template size and minimum font size on plots\n",
    "    \n",
    "    np.random.seed(seed=seed)\n",
    "    values = np.random.rand(max_L*2)*template-template/2.0\n",
    "    X_temp,Y_temp = np.split(values,2)\n",
    "    dftemp = pd.DataFrame(np.vstack((X_temp[:n],Y_temp[:n])).T,columns = ['X','Y'])\n",
    "    \n",
    "    cmap = matplotlib.cm.get_cmap('inferno')\n",
    "    \n",
    "    ax1 = plt.subplot(111)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.xlim([0, 22]); plt.ylim([0, 13])\n",
    "    \n",
    "    oxp = 2.0; oyp = 2.0; xprange = 10.0; yprange = 10.0          # location of histogram of averages\n",
    "    \n",
    "    nx = 50; ny = 50; xmin = 0; xmax = 1000; ymin = 0.0; ymax = 1000.0 # specify the grid\n",
    "    xrange = xmax - xmin; yrange = ymax - ymin\n",
    "    xsiz = xrange/nx; ysiz = yrange/ny\n",
    "    xmn = xmin + xsiz/2.0; ymn = ymin + ysiz/2.0; \n",
    "    xpmin = oxp; xpmax = oxp+xprange; ypmin = oyp; ypmax = oyp+yprange\n",
    "    xrange = xmax - xmin; yrange = ymax - ymin\n",
    "    xpsiz = xsiz*xprange/xrange; ypsiz = ysiz*yprange/yrange\n",
    "    \n",
    "    xcents = np.linspace(xmn,xmax-xsiz/2.0,nx)\n",
    "    ycents = np.linspace(ymax-ysiz/2.0,ymn,ny)\n",
    "    values = np.linspace(vmin,vmax,100)\n",
    "    \n",
    "    plt.plot([xpmin,xpmin,xpmax,xpmax,xpmin],[ypmin,ypmax,ypmax,ypmin,ypmin],color='black',lw = 1.0,zorder=200)\n",
    "    \n",
    "    gap = 0.1                                                     # pixelplot of image\n",
    "    for iy in range(0,ny):\n",
    "        ylowcorner = ycents[iy] - ysiz/2.0\n",
    "        yylowcorner = ((ylowcorner-ymin)/yrange*yprange)+ypmin + ypsiz*gap\n",
    "        for ix in range(0,nx):\n",
    "            #x = xmn + ix * xsiz\n",
    "            xlowcorner = xcents[ix] - xsiz/2.0\n",
    "            #xx = ((x-xmin)/xrange*xprange)+xpmin\n",
    "            xxlowcorner = ((xlowcorner-xmin)/xrange*xprange)+xpmin + xpsiz*gap\n",
    "            value = pfield[iy,ix]\n",
    "            color = (value - vmin)/(vmax-vmin)\n",
    "            ax1.add_patch(plt.Rectangle((xxlowcorner,yylowcorner), xpsiz*(1-2*gap), ypsiz*(1-2*gap), lw=0.1, fc = plt.cm.inferno(color),color='black',\n",
    "                                        zorder=10))\n",
    "    \n",
    "    nbin = 51                                                     # x axis\n",
    "    xbins = np.linspace(xmin,xmax,nbin)\n",
    "    for ibin, xbin in enumerate(xbins):\n",
    "        xx = ((xbin-xmin)/xrange*xprange)+xpmin\n",
    "        plt.plot([xx,xx],[ypmin,ypmax],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 5 == 0:\n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.02,ypmin],color='black',lw=1.0,zorder=3)\n",
    "            plt.annotate(int(np.round(xbin,0)),(xx,ypmin-yprange*0.05),ha='center',size=tsize)\n",
    "        else: \n",
    "            plt.plot([xx,xx],[ypmin-yprange*0.01,ypmin],color='black',lw=1.0,zorder=3)\n",
    "    \n",
    "    ybins = np.linspace(ymin,ymax,nbin)                           # y axis\n",
    "    for ibin, ybin in enumerate(ybins):\n",
    "        yy = ((ybin-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot([xpmin,xpmax],[yy,yy],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 5 == 0:\n",
    "            plt.plot([xpmin-xprange*0.02,xpmin],[yy,yy],color='black',lw=1.0,zorder=3)\n",
    "            plt.annotate(int(np.round(ybin,0)),(xpmin-xprange*0.05,yy),va='center',rotation=90.0,size=tsize)\n",
    "        else: \n",
    "            plt.plot([ypmin-yprange*0.01,ypmin],[yy,yy],color='black',lw=1.0,zorder=3)\n",
    "    \n",
    "    realizations = np.zeros((nreal,n)); xreals = np.zeros((nreal,n)); yreals = np.zeros((nreal,n))\n",
    "    np.random.seed(seed=seed)\n",
    "    dyo = np.random.rand(nreal)*(yrange - template) + template*0.5\n",
    "    dxo = np.random.rand(nreal)*(xrange - template) + template*0.5\n",
    "    dyyo = ((dyo-ymin)/yrange*yprange)+ypmin\n",
    "    dxxo = ((dxo-xmin)/xrange*xprange)+xpmin\n",
    "    \n",
    "    for i in range(0,nreal):                                      # get all realizations to ensure repeatability with seed\n",
    "        dftemp_real = dftemp.copy(deep = True)\n",
    "        dftemp_real['Y'] = dftemp_real['Y'] + dyo[i]\n",
    "        dftemp_real['X'] = dftemp_real['X'] + dxo[i]\n",
    "        dfspboot = GSLIB.sample(pfield, xmin, ymin, xsiz, 'Value',dftemp_real,'X','Y')\n",
    "        realizations[i,:] = dfspboot['Value']\n",
    "        xreals[i,:] = dftemp_real['X']; yreals[i,:] = dftemp_real['Y']\n",
    "        \n",
    "    dymin = dyo - template/2.0; dymax = dymin + template\n",
    "    dxmin = dxo - template/2.0; dxmax = dxmin + template\n",
    "    \n",
    "    dyymin = ((dymin-ymin)/yrange*yprange)+ypmin; dxxmin = ((dxmin-xmin)/xrange*xprange)+xpmin\n",
    "    dyymax = ((dymax-ymin)/yrange*yprange)+ypmin; dxxmax = ((dxmax-xmin)/xrange*xprange)+xpmin\n",
    "    \n",
    "    plt.plot([dxxmin[ireal-1],dxxmin[ireal-1],dxxmax[ireal-1],dxxmax[ireal-1],dxxmin[ireal-1]], # plot data template extents\n",
    "             [dyymin[ireal-1],dyymax[ireal-1],dyymax[ireal-1],dyymin[ireal-1],dyymin[ireal-1]],color='black',lw = 1.0,zorder=200)\n",
    "    plt.plot([dxxmin[ireal-1],dxxmin[ireal-1],dxxmax[ireal-1],dxxmax[ireal-1],dxxmin[ireal-1]], # plot data template extents\n",
    "             [dyymin[ireal-1],dyymax[ireal-1],dyymax[ireal-1],dyymin[ireal-1],dyymin[ireal-1]],color='white',lw = 3.0,zorder=190)\n",
    "    plt.scatter(dxxo[ireal-1],dyyo[ireal-1],marker='x',color='black',s=40,zorder=200)\n",
    "    \n",
    "    yy = ((yreals[ireal-1,:]-ymin)/yrange*yprange)+ypmin\n",
    "    xx = ((xreals[ireal-1,:]-xmin)/xrange*xprange)+xpmin\n",
    "    vals = (realizations[ireal-1,:] - vmin)/(vmax - vmin)\n",
    "    \n",
    "    plt.scatter(xx,yy,c=vals,edgecolor=None,marker='o',lw=1,s=15,alpha=1.0,\n",
    "                vmin=0.0,vmax=1.0,cmap=cmap,zorder=300) \n",
    "    plt.scatter(xx,yy,color='black',edgecolor='white',marker='o',lw=3,s=22,alpha=1.0,zorder=299)\n",
    "    plt.scatter(xx,yy,color='white',edgecolor='black',marker='o',lw=5,s=23,alpha=1.0,zorder=298)        \n",
    "    \n",
    "    plt.annotate('X (m)',(xpmin + xprange*0.5,ypmin - yprange*0.1),ha = 'center',size=tsize*1.6)\n",
    "    plt.annotate('Y (m)',(xpmin - xprange*0.1,ypmin + yprange*0.5),rotation = 90.0,va = 'center',size=tsize*1.6)\n",
    "    plt.annotate('Lithium Model with Spatial Bootstrap Realization',(xpmin + xprange*0.5,ypmax + yprange*0.02),ha = 'center',size=tsize*1.6)\n",
    "    \n",
    "    #### Bootstrap Histogram\n",
    "    \n",
    "    oxp = 15.0; oyp = 8.0; xprange = 6.0; yprange = 3.0           # location of histogram of bootstrap realization\n",
    "    nbin = 21; xmin = 0; xmax = 1000; ymin = 0.0; ymax = 15.0     # specify the grid\n",
    "    xrange = xmax - xmin; yrange = ymax - ymin\n",
    "    \n",
    "    plt.plot([oxp,oxp+xprange],[oyp,oyp],color='black'); plt.plot([oxp,oxp],[oyp,oyp+yprange],color='black')\n",
    "        \n",
    "    xpmin = oxp; xpmax = oxp+xprange; ypmin = oyp; ypmax = oyp+yprange\n",
    "    vhalf = (vmax-vmin)/(nbin-1)/2.0; vsize = vhalf*2.0\n",
    "    vrange = vmax - vmin; yrange = ymax - ymin\n",
    "    vvhalf = vhalf*xprange/vrange; vvsize = vsize*xprange/vrange \n",
    "\n",
    "    vbins = np.linspace(vmin,vmax,nbin)\n",
    "    ybins = np.linspace(ymin,maxfboot,11)\n",
    "    vcents = np.linspace(vmin + vhalf,vmax-vhalf,nbin-1)\n",
    "    \n",
    "    for ibin, vbin in enumerate(vbins):\n",
    "        vv = ((vbin-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vv,vv],[ypmin,ypmax],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 2 == 0:\n",
    "            plt.plot([vv,vv],[ypmin-yprange*0.1,ypmin],lw=0.4,color='black',zorder=3)\n",
    "            plt.annotate(int(np.round(vbin,0)),(vv,ypmin-yprange*0.23),ha='center',size=tsize)\n",
    "        else: \n",
    "            plt.plot([vv,vv],[ypmin-yprange*0.05,ypmin],lw=0.4,color='black',zorder=3)\n",
    "            plt.annotate(int(np.round(vbin,0)),(vv,ypmin-yprange*0.13),ha='center',size=tsize)   \n",
    "                 \n",
    "    for ybin in ybins:\n",
    "        yy = ((ybin-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot([xpmin-xprange*0.02,xpmin],[yy,yy],color='black',lw=0.4,zorder=3)\n",
    "        plt.plot([xpmin,xpmax],[yy,yy],color='grey',lw=0.4,zorder=1)\n",
    "        plt.annotate(int(np.round(ybin,0)),(xpmin-xprange*0.05,yy),ha='right',size=tsize)\n",
    "    \n",
    "    histboot = np.histogram(realizations[ireal-1,:], bins=vbins, weights=None)[0]\n",
    "    \n",
    "    average = np.average(realizations[ireal-1,:])\n",
    "    \n",
    "    for ibin, prop in enumerate(histboot):\n",
    "        vv = ((vcents[ibin]-vmin)/vrange*xprange)+xpmin\n",
    "    #     print(vv)\n",
    "        yy = histboot[ibin]*yprange/maxfboot\n",
    "    #     print(yy)\n",
    "        ax1.add_patch(plt.Rectangle((vv-vvhalf,ypmin), vvsize, yy, lw=1, fc = 'darkorange',color='black', ))\n",
    "        vavg = ((average-vmin)/vrange*xprange)+xpmin\n",
    "        \n",
    "    for ipts in range(0,n):\n",
    "        vv = ((realizations[ireal-1,ipts]-vmin)/vrange*xprange)+xpmin \n",
    "        plt.scatter(vv,ypmin,color='red',edgecolor='black',s=20,alpha=1.0,zorder=100)\n",
    "        \n",
    "    plot_avg = True\n",
    "    if plot_avg:\n",
    "        vv = ((np.average(realizations[ireal-1,:])-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vv,vv],[ypmin,ypmax],color='red',lw=2,ls='--')\n",
    "        plt.annotate(r'$\\overline{x}^{\\ell} = $' + str(int(np.round(np.average(realizations[ireal-1,:]),0))),\n",
    "                     (vv,ypmin+yprange*0.6),color='red',rotation=270,size=tsize*1.2)\n",
    "        \n",
    "    plt.annotate('Spatial Bootstrap Distribution Realization #' + str(ireal),(xpmin+xprange*0.5,ypmax+yprange*0.08),ha='center',size=tsize*1.6) \n",
    "    plt.annotate('Lithium Grade (ppm)',(xpmin+xprange*0.5,ypmin-yprange*0.4),ha='center',size=tsize*1.6) \n",
    "    plt.annotate('Frequency',(xpmin-xprange*0.14,ypmin+yprange*0.5),va='center',rotation = 90.0,size=tsize*1.6)   \n",
    "    \n",
    "    oxp = 15.0; oyp = 3.0; xprange = 6.0; yprange = 3.0           # location of histogram of averages\n",
    "    nbin = 21; ymin = 0.0; ymax = 15.0\n",
    "    xpmin = oxp; xpmax = oxp+xprange; ypmin = oyp; ypmax = oyp+yprange\n",
    "    vhalf = (vmax-vmin)/(nbin-1)/2.0; vsize = vhalf*2.0\n",
    "    vvhalf = vhalf*xprange/vrange; vvsize = vsize*xprange/vrange \n",
    "    vrange = vmax - vmin; yrange = ymax - ymin\n",
    "    vbins = np.linspace(vmin,vmax,nbin)\n",
    "    ybins = np.linspace(ymin,maxfboot,11)\n",
    "    vcents = np.linspace(vmin + vhalf,vmax-vhalf,nbin-1)\n",
    "    \n",
    "    plt.plot([oxp,oxp+xprange],[oyp,oyp],color='black'); plt.plot([oxp,oxp],[oyp,oyp+yprange],color='black')\n",
    "    \n",
    "    for ibin, vbin in enumerate(vbins):\n",
    "        vv = ((vbin-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vv,vv],[ypmin,ypmax],color='grey',lw=0.2,zorder=1)\n",
    "        if ibin % 2 == 0:\n",
    "            plt.plot([vv,vv],[ypmin-yprange*0.1,ypmin],lw=0.4,color='black',zorder=3)\n",
    "            plt.annotate(int(np.round(vbin,0)),(vv,ypmin-yprange*0.23),ha='center',size=tsize)\n",
    "        else: \n",
    "            plt.plot([vv,vv],[ypmin-yprange*0.05,ypmin],lw=0.4,color='black',zorder=3)\n",
    "            plt.annotate(int(np.round(vbin,0)),(vv,ypmin-yprange*0.13),ha='center',size=tsize)   \n",
    "                 \n",
    "    for ybin in ybins:\n",
    "        yy = ((ybin-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot([xpmin-xprange*0.02,xpmin],[yy,yy],color='black',lw=0.4,zorder=3)\n",
    "        plt.plot([xpmin,xpmax],[yy,yy],color='grey',lw=0.4,zorder=1)\n",
    "        plt.annotate(int(np.round(ybin,0)),(xpmin-xprange*0.05,yy),ha='right',size=tsize)\n",
    "        \n",
    "    averages = np.average(realizations,axis=1)\n",
    "    # print(realizations)\n",
    "    average = np.average(averages[:ireal])\n",
    "    hist_avg = np.histogram(averages[:ireal], bins=vbins, weights=None)[0]\n",
    "    for ibin, prop in enumerate(histboot):\n",
    "        vv = ((vcents[ibin]-vmin)/vrange*xprange)+xpmin\n",
    "        yy = hist_avg[ibin]*yprange/maxfboot\n",
    "        ax1.add_patch(plt.Rectangle((vv-vvhalf,ypmin), vvsize, yy, lw=1, fc = 'gold',color='black',zorder=20))\n",
    "        vavg = ((average-vmin)/vrange*xprange)+xpmin\n",
    "\n",
    "    if ireal > 1:\n",
    "        hist_avg = np.histogram(averages[:ireal-1], bins=vbins, weights=None)[0]\n",
    "        for ibin, prop in enumerate(histboot):\n",
    "            vv = ((vcents[ibin]-vmin)/vrange*xprange)+xpmin\n",
    "            yy = hist_avg[ibin]*yprange/maxfboot\n",
    "            ax1.add_patch(plt.Rectangle((vv-vvhalf,ypmin), vvsize, yy, lw=1, fc = 'darkorange',color='black',zorder=25))\n",
    "            vavg = ((average-vmin)/vrange*xprange)+xpmin\n",
    "        \n",
    "    plt.annotate('Spatial Bootstrap Average Realizations',(xpmin+xprange*0.5,ypmax+yprange*0.08),ha='center',size=tsize*1.6) \n",
    "    plt.annotate('Bootstrap Average Lithium Grade (ppm)',(xpmin+xprange*0.5,ypmin-yprange*0.40),ha='center',size=tsize*1.6) \n",
    "    plt.annotate('Frequency',(xpmin-xprange*0.14,ypmin+yprange*0.5),va='center',rotation = 90.0,size=tsize*1.6) \n",
    "    \n",
    "    mean = np.average(averages[:ireal]); stdev = np.std(averages[:ireal])\n",
    "    P10 = np.percentile(averages[:ireal],10); P90 = np.percentile(averages[:ireal],90)\n",
    "    plt.annotate('Spatial Bootstrap Uncertainty in Mean:',(0,0.8),size=tsize*1.6,zorder=400)\n",
    "    plt.annotate('Mean: ' + str(np.round(mean,2)),(0,0.4),ha='left',size=tsize*1.4,zorder=400)\n",
    "    plt.annotate('St.Dev.: ' + str(np.round(stdev,2)),(2.0,0.4),ha='left',size=tsize*1.4,zorder=400)\n",
    "    plt.annotate('P10: ' + str(np.round(P10,2)),(0.0,0.0),ha='left',size=tsize*1.4,zorder=400)\n",
    "    plt.annotate('P90: ' + str(np.round(P90,2)),(2.0,0.0),ha='left',size=tsize*1.4,zorder=400)\n",
    "    \n",
    "    if ireal > 1:\n",
    "        vvmean = ((mean-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vvmean,vvmean],[ypmin,ypmax],color='red',lw=2.0,zorder=200)\n",
    "        plt.annotate('Mean: ' + str(np.round(mean,2)),(vvmean,ypmin+yprange*0.9),rotation=270.0,color='red',va='top',size=tsize*1.3,zorder=200)\n",
    "        \n",
    "        vvP10 = ((P10-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vvP10,vvP10],[ypmin,ypmax],color='red',lw=2.0,ls='--',zorder=200)\n",
    "        plt.annotate('P10: ' + str(np.round(P10,2)),(vvP10,ypmin+yprange*0.9),rotation=270.0,color='red',va='top',size=tsize*1.3,zorder=200)\n",
    "        \n",
    "        vvP90 = ((P90-vmin)/vrange*xprange)+xpmin\n",
    "        plt.plot([vvP90,vvP90],[ypmin,ypmax],color='red',lw=2.0,ls='--',zorder=200)\n",
    "        plt.annotate('P90: ' + str(np.round(P90,2)),(vvP90,ypmin+yprange*0.9),rotation=270.0,color='red',va='top',size=tsize*1.3,zorder=200)\n",
    "    \n",
    "    if ireal > 5:\n",
    "        PDFModel = sm.nonparametric.KDEUnivariate(averages[:ireal]).fit()\n",
    "        yPDF = PDFModel.evaluate(values)*len(averages[:ireal])*vsize\n",
    "        vvalues = ((values-vmin)/vrange*xprange)+xpmin; yyPDF = ((yPDF-ymin)/yrange*yprange)+ypmin\n",
    "        plt.plot(vvalues,yyPDF,color='black',zorder=100)\n",
    "\n",
    "    fraction = 0.01\n",
    "    norm = mpl.colors.Normalize(vmin=vmin,vmax=vmax)\n",
    "    cbar = ax1.figure.colorbar(\n",
    "            mpl.cm.ScalarMappable(norm=norm, cmap='inferno'),\n",
    "            ax=ax1, pad=-0.78, extend='both', fraction=fraction)\n",
    "\n",
    "    ticklabs = cbar.ax.get_yticklabels()\n",
    "    cbar.ax.set_yticklabels(ticklabs, fontsize=6)\n",
    "    \n",
    "    plt.annotate('Lithium Grade (ppm)',(13.4,6.5),rotation=270.0,va='center',size=tsize*1.2)\n",
    "        \n",
    "    \n",
    "    plt.subplots_adjust(left=0.0, bottom=0.0, right=0.7, top=1.0, wspace=0.2, hspace=0.2)\n",
    "    #plt.savefig('SpatialBootstrap.jpg',dpi=600,bbox_inches='tight')  \n",
    "    plt.show()\n",
    "      \n",
    "interactive_plot3 = widgets.interactive_output(f_make3, {'n':n,'ireal':ireal,'seed':seed})\n",
    "interactive_plot3.clear_output(wait = True)                # reduce flickering by delaying plot updating     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7873912f866b499baeba3e5936c4e056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Text(value='                Spatial Bootstrap, Resampling from Images or Models for Uncertaintyâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e502b35abbe46beb5ba6eb6bcb2258b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(ui_all3, interactive_plot3)                            # display the interactive plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "This was an interactive demonstration spatial bootstrap.\n",
    "  \n",
    "I hope this was helpful,\n",
    "\n",
    "*Michael*\n",
    "\n",
    "#### The Author:\n",
    "\n",
    "### Michael Pyrcz, Professor, The University of Texas at Austin \n",
    "*Novel Data Analytics, Geostatistics and Machine Learning Subsurface Solutions*\n",
    "\n",
    "With over 17 years of experience in subsurface consulting, research and development, Michael has returned to academia driven by his passion for teaching and enthusiasm for enhancing engineers' and geoscientists' impact in subsurface resource development. \n",
    "\n",
    "For more about Michael check out these links:\n",
    "\n",
    "#### [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)\n",
    "\n",
    "#### Want to Work Together?\n",
    "\n",
    "I hope this content is helpful to those that want to learn more about subsurface modeling, data analytics and machine learning. Students and working professionals are welcome to participate.\n",
    "\n",
    "* Want to invite me to visit your company for training, mentoring, project review, workflow design and / or consulting? I'd be happy to drop by and work with you! \n",
    "\n",
    "* Interested in partnering, supporting my graduate student research or my Subsurface Data Analytics and Machine Learning consortium (co-PIs including Profs. Foster, Torres-Verdin and van Oort)? My research combines data analytics, stochastic modeling and machine learning theory with practice to develop novel methods and workflows to add value. We are solving challenging subsurface problems!\n",
    "\n",
    "* I can be reached at mpyrcz@austin.utexas.edu.\n",
    "\n",
    "I'm always happy to discuss,\n",
    "\n",
    "*Michael*\n",
    "\n",
    "Michael Pyrcz, Ph.D., P.Eng. Professor, Cockrell School of Engineering and The Jackson School of Geosciences, The University of Texas at Austin\n",
    "\n",
    "#### More Resources Available at: [Twitter](https://twitter.com/geostatsguy) | [GitHub](https://github.com/GeostatsGuy) | [Website](http://michaelpyrcz.com) | [GoogleScholar](https://scholar.google.com/citations?user=QVZ20eQAAAAJ&hl=en&oi=ao) | [Book](https://www.amazon.com/Geostatistical-Reservoir-Modeling-Michael-Pyrcz/dp/0199731446) | [YouTube](https://www.youtube.com/channel/UCLqEr-xV-ceHdXXXrTId5ig)  | [LinkedIn](https://www.linkedin.com/in/michael-pyrcz-61a648a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
